{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) If a person playfully insults their friends, how does the probability of being left-handed change?\n",
    "\n",
    "2) If a person enjoys dancing alone, how does the probability of being left-handed change?\n",
    "\n",
    "3) If a person hates shopping, how does the probability of being left-handed change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder\n",
    "\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  ...  country  fromgoogle  engnat  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1  ...       US           2       1   \n",
       "1   1   5   1   4   2   5   5   4   1    5  ...       CA           2       1   \n",
       "2   1   2   1   1   5   4   3   2   1    4  ...       NL           2       2   \n",
       "3   1   4   1   5   1   4   5   4   3    5  ...       US           2       1   \n",
       "4   5   1   5   1   5   1   5   1   3    1  ...       US           2       1   \n",
       "\n",
       "   age  education  gender  orientation  race  religion  hand  \n",
       "0   22          3       1            1     3         2     3  \n",
       "1   14          1       2            2     6         1     1  \n",
       "2   30          4       1            1     1         1     2  \n",
       "3   18          2       2            5     3         2     2  \n",
       "4   22          3       1            1     3         2     3  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_hand = pd.read_csv(filepath_or_buffer = './data.csv', sep='\\t')\n",
    "left_hand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would keep the following columns hidden/anonymous:\n",
    "1) Gender\n",
    "\n",
    "2) Sexual Orientation\n",
    "\n",
    "3) Religion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4184 entries, 0 to 4183\n",
      "Data columns (total 56 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q1           4184 non-null   int64 \n",
      " 1   Q2           4184 non-null   int64 \n",
      " 2   Q3           4184 non-null   int64 \n",
      " 3   Q4           4184 non-null   int64 \n",
      " 4   Q5           4184 non-null   int64 \n",
      " 5   Q6           4184 non-null   int64 \n",
      " 6   Q7           4184 non-null   int64 \n",
      " 7   Q8           4184 non-null   int64 \n",
      " 8   Q9           4184 non-null   int64 \n",
      " 9   Q10          4184 non-null   int64 \n",
      " 10  Q11          4184 non-null   int64 \n",
      " 11  Q12          4184 non-null   int64 \n",
      " 12  Q13          4184 non-null   int64 \n",
      " 13  Q14          4184 non-null   int64 \n",
      " 14  Q15          4184 non-null   int64 \n",
      " 15  Q16          4184 non-null   int64 \n",
      " 16  Q17          4184 non-null   int64 \n",
      " 17  Q18          4184 non-null   int64 \n",
      " 18  Q19          4184 non-null   int64 \n",
      " 19  Q20          4184 non-null   int64 \n",
      " 20  Q21          4184 non-null   int64 \n",
      " 21  Q22          4184 non-null   int64 \n",
      " 22  Q23          4184 non-null   int64 \n",
      " 23  Q24          4184 non-null   int64 \n",
      " 24  Q25          4184 non-null   int64 \n",
      " 25  Q26          4184 non-null   int64 \n",
      " 26  Q27          4184 non-null   int64 \n",
      " 27  Q28          4184 non-null   int64 \n",
      " 28  Q29          4184 non-null   int64 \n",
      " 29  Q30          4184 non-null   int64 \n",
      " 30  Q31          4184 non-null   int64 \n",
      " 31  Q32          4184 non-null   int64 \n",
      " 32  Q33          4184 non-null   int64 \n",
      " 33  Q34          4184 non-null   int64 \n",
      " 34  Q35          4184 non-null   int64 \n",
      " 35  Q36          4184 non-null   int64 \n",
      " 36  Q37          4184 non-null   int64 \n",
      " 37  Q38          4184 non-null   int64 \n",
      " 38  Q39          4184 non-null   int64 \n",
      " 39  Q40          4184 non-null   int64 \n",
      " 40  Q41          4184 non-null   int64 \n",
      " 41  Q42          4184 non-null   int64 \n",
      " 42  Q43          4184 non-null   int64 \n",
      " 43  Q44          4184 non-null   int64 \n",
      " 44  introelapse  4184 non-null   int64 \n",
      " 45  testelapse   4184 non-null   int64 \n",
      " 46  country      4184 non-null   object\n",
      " 47  fromgoogle   4184 non-null   int64 \n",
      " 48  engnat       4184 non-null   int64 \n",
      " 49  age          4184 non-null   int64 \n",
      " 50  education    4184 non-null   int64 \n",
      " 51  gender       4184 non-null   int64 \n",
      " 52  orientation  4184 non-null   int64 \n",
      " 53  race         4184 non-null   int64 \n",
      " 54  religion     4184 non-null   int64 \n",
      " 55  hand         4184 non-null   int64 \n",
      "dtypes: int64(55), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "left_hand.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>...</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.962715</td>\n",
       "      <td>3.829589</td>\n",
       "      <td>2.846558</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>2.865440</td>\n",
       "      <td>3.672084</td>\n",
       "      <td>3.216539</td>\n",
       "      <td>3.184512</td>\n",
       "      <td>2.761233</td>\n",
       "      <td>3.522945</td>\n",
       "      <td>...</td>\n",
       "      <td>479.994503</td>\n",
       "      <td>1.576243</td>\n",
       "      <td>1.239962</td>\n",
       "      <td>30.370698</td>\n",
       "      <td>2.317878</td>\n",
       "      <td>1.654398</td>\n",
       "      <td>1.833413</td>\n",
       "      <td>5.013623</td>\n",
       "      <td>2.394359</td>\n",
       "      <td>1.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.360291</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>1.664804</td>\n",
       "      <td>1.476879</td>\n",
       "      <td>1.545798</td>\n",
       "      <td>1.342238</td>\n",
       "      <td>1.490733</td>\n",
       "      <td>1.387382</td>\n",
       "      <td>1.511805</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>...</td>\n",
       "      <td>3142.178542</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.440882</td>\n",
       "      <td>367.201726</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>1.303454</td>\n",
       "      <td>1.970996</td>\n",
       "      <td>2.184164</td>\n",
       "      <td>0.495357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>324.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>119834.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23763.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q1           Q2           Q3           Q4           Q5  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      1.962715     3.829589     2.846558     3.186902     2.865440   \n",
       "std       1.360291     1.551683     1.664804     1.476879     1.545798   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     3.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000     5.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.000000     5.000000     5.000000     5.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "                Q6           Q7           Q8           Q9          Q10  ...  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000  ...   \n",
       "mean      3.672084     3.216539     3.184512     2.761233     3.522945  ...   \n",
       "std       1.342238     1.490733     1.387382     1.511805     1.242890  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     3.000000  ...   \n",
       "50%       4.000000     3.000000     3.000000     3.000000     4.000000  ...   \n",
       "75%       5.000000     5.000000     4.000000     4.000000     5.000000  ...   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000  ...   \n",
       "\n",
       "          testelapse   fromgoogle       engnat           age    education  \\\n",
       "count    4184.000000  4184.000000  4184.000000   4184.000000  4184.000000   \n",
       "mean      479.994503     1.576243     1.239962     30.370698     2.317878   \n",
       "std      3142.178542     0.494212     0.440882    367.201726     0.874264   \n",
       "min         7.000000     1.000000     0.000000     13.000000     0.000000   \n",
       "25%       186.000000     1.000000     1.000000     18.000000     2.000000   \n",
       "50%       242.000000     2.000000     1.000000     21.000000     2.000000   \n",
       "75%       324.250000     2.000000     1.000000     27.000000     3.000000   \n",
       "max    119834.000000     2.000000     2.000000  23763.000000     4.000000   \n",
       "\n",
       "            gender  orientation         race     religion         hand  \n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000  \n",
       "mean      1.654398     1.833413     5.013623     2.394359     1.190966  \n",
       "std       0.640915     1.303454     1.970996     2.184164     0.495357  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     1.000000     5.000000     1.000000     1.000000  \n",
       "50%       2.000000     1.000000     6.000000     2.000000     1.000000  \n",
       "75%       2.000000     2.000000     6.000000     2.000000     1.000000  \n",
       "max       3.000000     5.000000     7.000000     7.000000     3.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_hand.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification because we are determining the probability between three options. It is a discrete variable we are solving for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we want to standardize variables when the features have a very wide range of values. The Titanic dataset from a previous lab would be a good example of a dataset we would need to standardize variables because they asked for age, count of siblings, price of ticket, etc. All of these features have different ranges and measurements, so they need to be put on the same scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wouldn't standardize our variables when every feature is on the same scale or measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because questions 1-44 are all based on the same answer scale of 1-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 11 zeros, which is not associated with a possible answer to the question. Since it's impossible to determine these, I will drop the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3542\n",
       "2     452\n",
       "3     179\n",
       "0      11\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_hand['hand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3542\n",
       "2     452\n",
       "3     179\n",
       "Name: hand, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_cleaned = left_hand[left_hand['hand'] > 0]\n",
    "hand_cleaned['hand'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shouldn't should an even number for k because if there is a tie, sklearn does not handle it in a logical way. It is always best to use an odd number so there will be a clear winner.cross_val_score(knn, X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 7$, and one with $k = 9$.\n",
    "\n",
    "> Instantiate and fit your models using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hand_cleaned.iloc[:, :44]\n",
    "y = hand_cleaned['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [3, 5, 7, 9]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(KNeighborsClassifier(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7, 9]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.087494</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.851438</td>\n",
       "      <td>0.840256</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.846596</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.007656</td>\n",
       "      <td>0.087492</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.849840</td>\n",
       "      <td>0.837061</td>\n",
       "      <td>0.843450</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>0.844679</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.096868</td>\n",
       "      <td>0.006251</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.841853</td>\n",
       "      <td>0.841853</td>\n",
       "      <td>0.830671</td>\n",
       "      <td>0.832268</td>\n",
       "      <td>0.8336</td>\n",
       "      <td>0.836049</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004105</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.084951</td>\n",
       "      <td>0.016863</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.835463</td>\n",
       "      <td>0.830671</td>\n",
       "      <td>0.787540</td>\n",
       "      <td>0.816294</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>0.815274</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.003125      0.006250         0.087494        0.007652   \n",
       "2       0.009377      0.007656         0.087492        0.018748   \n",
       "1       0.006249      0.007654         0.096868        0.006251   \n",
       "0       0.004105      0.006066         0.084951        0.016863   \n",
       "\n",
       "  param_n_neighbors              params  split0_test_score  split1_test_score  \\\n",
       "3                 9  {'n_neighbors': 9}           0.848243           0.851438   \n",
       "2                 7  {'n_neighbors': 7}           0.848243           0.849840   \n",
       "1                 5  {'n_neighbors': 5}           0.841853           0.841853   \n",
       "0                 3  {'n_neighbors': 3}           0.835463           0.830671   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "3           0.840256           0.848243             0.8448         0.846596   \n",
       "2           0.837061           0.843450             0.8448         0.844679   \n",
       "1           0.830671           0.832268             0.8336         0.836049   \n",
       "0           0.787540           0.816294             0.8064         0.815274   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "3        0.003802                1  \n",
       "2        0.004448                2  \n",
       "1        0.004829                3  \n",
       "0        0.017284                4  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. How does a null model do? Create a null model. Does it do better than our best KNN model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.848790\n",
       "2    0.108315\n",
       "3    0.042895\n",
       "Name: hand, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_cleaned['hand'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the highest percentage of the split is 84.9%, our best KNN model is about the same because the mean test score tells use we are 84.6% accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. \n",
    "\n",
    "Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, regularization is applied by default. The default parameters are penalty='l2' and C=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, because they are all on the same 5 point scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Let's use logistic regression to predict whether the person is left-handed.\n",
    "\n",
    "\n",
    "Be sure to use the same train/test split with your data as with your kNN model above!\n",
    "\n",
    "Search over the following hyperparameters:\n",
    "\n",
    "- l2 regularization with C = [.001, .01, .1, 1, 10, 100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lindsey\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'C': [.001, .01, .1, 1, 10, 100]}\n",
    "gs2 = GridSearchCV(LogisticRegression(), params, n_jobs = -1)\n",
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.001}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.399324</td>\n",
       "      <td>0.048464</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.849840</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.849153</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.301154</td>\n",
       "      <td>0.011464</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.01}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.848834</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.296858</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.845048</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296860</td>\n",
       "      <td>0.013974</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 1}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.845048</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287479</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 10}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.845048</td>\n",
       "      <td>0.846645</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.847555</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.271856</td>\n",
       "      <td>0.023384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{'C': 100}</td>\n",
       "      <td>0.84984</td>\n",
       "      <td>0.848243</td>\n",
       "      <td>0.845048</td>\n",
       "      <td>0.846645</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.847555</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.399324      0.048464         0.009798        0.008037   0.001   \n",
       "1       0.301154      0.011464         0.009374        0.007654    0.01   \n",
       "2       0.296858      0.009880         0.006250        0.007654     0.1   \n",
       "3       0.296860      0.013974         0.003123        0.006246       1   \n",
       "4       0.287479      0.007655         0.006250        0.007655      10   \n",
       "5       0.271856      0.023384         0.000000        0.000000     100   \n",
       "\n",
       "         params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'C': 0.001}            0.84984           0.849840           0.848243   \n",
       "1   {'C': 0.01}            0.84984           0.848243           0.848243   \n",
       "2    {'C': 0.1}            0.84984           0.848243           0.845048   \n",
       "3      {'C': 1}            0.84984           0.848243           0.845048   \n",
       "4     {'C': 10}            0.84984           0.848243           0.845048   \n",
       "5    {'C': 100}            0.84984           0.848243           0.845048   \n",
       "\n",
       "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.848243             0.8496         0.849153        0.000749   \n",
       "1           0.848243             0.8496         0.848834        0.000728   \n",
       "2           0.848243             0.8480         0.847875        0.001558   \n",
       "3           0.848243             0.8480         0.847875        0.001558   \n",
       "4           0.846645             0.8480         0.847555        0.001613   \n",
       "5           0.846645             0.8480         0.847555        0.001613   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "1                2  \n",
       "2                3  \n",
       "3                3  \n",
       "4                5  \n",
       "5                5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs2.cv_results_).sort_values(by = 'rank_test_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 16. Before calculating any score on your data, take a step back. \n",
    "\n",
    "Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not think any of the variables used would do a good job predicting the y variable. The questions seem arbitrary and do not relate to what hand a person uses. I think this will have no affect on my scores and the model will randomly guess, being correct the same amount as if someone guessed right-handed every single time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Using accuracy as your metric, evaluate the best of your models on both the training (mean validation) and testing sets. Put your scores below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8497922658996484"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8467432950191571"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849153084052413"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression(C = 0.001, max_iter = 1000)\n",
    "logr.fit(X_train, y_train)\n",
    "logr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If k is a low number, there is high bias and low variance. As k increases the bias decreases, but then the variance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Increase k to include more neighbors to compare to.\n",
    "\n",
    "2) Decrease number of parameters used.\n",
    "\n",
    "3) Adjust the weights parameter to make the sample more fair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the C parameter increases the number of points allowed in the training data,  which increases the bias but decreases the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02647748,  0.00227431, -0.02106437, -0.01572645, -0.01458586,\n",
       "         0.0146163 , -0.01653068,  0.01775094,  0.00842678,  0.00570285,\n",
       "        -0.00752813,  0.00563831, -0.00716644,  0.01529073,  0.00851352,\n",
       "         0.00089831, -0.01539418,  0.02375612, -0.00410477,  0.00731733,\n",
       "         0.01003156,  0.0229166 ,  0.03392933, -0.00019402, -0.01690437,\n",
       "        -0.02512919, -0.01148535, -0.02324191, -0.0135265 ,  0.00416453,\n",
       "        -0.01036909,  0.00309361, -0.01230219, -0.02029108, -0.05055796,\n",
       "         0.01097466,  0.0102912 , -0.0132055 ,  0.01201209,  0.01601534,\n",
       "         0.02470312,  0.00078419,  0.00679167, -0.0251883 ],\n",
       "       [-0.01444559, -0.00353495, -0.01472095, -0.02506887,  0.01304466,\n",
       "         0.00458398,  0.00319661, -0.04373303, -0.02566687,  0.01929735,\n",
       "         0.00350209, -0.00970357, -0.01568526, -0.00942392, -0.0082956 ,\n",
       "        -0.00445964, -0.0025971 , -0.0151911 , -0.00302204, -0.00417585,\n",
       "         0.01200015, -0.02622951, -0.01819325,  0.00197109,  0.00481692,\n",
       "         0.00824884, -0.0176385 ,  0.00109286,  0.01186805,  0.01039938,\n",
       "         0.01030421, -0.00554184, -0.00873173, -0.00088982, -0.01711064,\n",
       "        -0.01845117, -0.01813197, -0.00116563, -0.01723339, -0.02162675,\n",
       "        -0.0156777 , -0.02449859, -0.02887476, -0.01148619],\n",
       "       [ 0.04092307,  0.00126065,  0.03578532,  0.04079532,  0.00154119,\n",
       "        -0.01920028,  0.01333407,  0.02598209,  0.01724009, -0.02500019,\n",
       "         0.00402604,  0.00406526,  0.02285169, -0.00586681, -0.00021792,\n",
       "         0.00356133,  0.01799128, -0.00856502,  0.00712681, -0.00314147,\n",
       "        -0.02203171,  0.0033129 , -0.01573608, -0.00177707,  0.01208745,\n",
       "         0.01688036,  0.02912385,  0.02214905,  0.00165845, -0.01456391,\n",
       "         0.00006488,  0.00244823,  0.02103392,  0.0211809 ,  0.0676686 ,\n",
       "         0.00747651,  0.00784076,  0.01437113,  0.00522131,  0.00561141,\n",
       "        -0.00902542,  0.0237144 ,  0.02208309,  0.03667449]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "logr = LogisticRegression(C = 0.001, max_iter = 1000)\n",
    "logr.fit(X_train, y_train)\n",
    "logr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0561403 , -0.00144918, -0.04068638, -0.0493929 , -0.0051921 ,\n",
       "         0.03050978, -0.02675265,  0.02680686,  0.01571866,  0.03666667,\n",
       "        -0.02267011,  0.00115206, -0.02248339,  0.04593655,  0.0166111 ,\n",
       "         0.00165679, -0.02481118,  0.04068063, -0.0185483 ,  0.00511964,\n",
       "         0.05499295,  0.05030146,  0.07984453, -0.0014914 , -0.03886053,\n",
       "        -0.04825997, -0.11204434, -0.05597151, -0.00447222,  0.01879691,\n",
       "        -0.00076147,  0.00610227, -0.04193369, -0.04709328, -0.15108379,\n",
       "         0.04118014,  0.0222776 , -0.01917264,  0.04960074,  0.00857752,\n",
       "         0.06179508,  0.00739092,  0.09029712, -0.08350082],\n",
       "       [-0.06379197, -0.00097435, -0.03647512, -0.09018742,  0.06026943,\n",
       "         0.03524933,  0.01552488, -0.14501193, -0.0597005 ,  0.1012702 ,\n",
       "        -0.00911715, -0.02397286, -0.05769045,  0.03435334, -0.00179241,\n",
       "        -0.00372027,  0.00185711, -0.02624684, -0.01300575, -0.00660276,\n",
       "        -0.00015287, -0.05013721,  0.00068886,  0.00354734,  0.01057631,\n",
       "         0.02856444, -0.02627092, -0.01382013,  0.06115587,  0.05105205,\n",
       "         0.04363517, -0.01182141, -0.06289048, -0.00608539, -0.12043458,\n",
       "        -0.00044348, -0.03444907,  0.01418706,  0.00258455, -0.07770607,\n",
       "         0.00174881, -0.05003532, -0.07391353, -0.06833624],\n",
       "       [ 0.11993228,  0.00242354,  0.0771615 ,  0.13958032, -0.05507732,\n",
       "        -0.06575911,  0.01122776,  0.11820507,  0.04398184, -0.13793687,\n",
       "         0.03178726,  0.0228208 ,  0.08017384, -0.08028989, -0.01481868,\n",
       "         0.00206348,  0.02295407, -0.01443379,  0.03155405,  0.00148313,\n",
       "        -0.05484009, -0.00016425, -0.08053338, -0.00205594,  0.02828422,\n",
       "         0.01969553,  0.13831526,  0.06979164, -0.05668365, -0.06984896,\n",
       "        -0.0428737 ,  0.00571914,  0.10482417,  0.05317867,  0.27151837,\n",
       "        -0.04073666,  0.01217147,  0.00498558, -0.05218529,  0.06912854,\n",
       "        -0.06354389,  0.04264441, -0.01638359,  0.15183706]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "logr2 = LogisticRegression(C = 100, max_iter = 1000)\n",
    "logr2.fit(X_train, y_train)\n",
    "logr2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the grid search above, it looks like the mean test score decreases as we increase C. This means that the model works a little bit better when it is more regularized. The test scores also become more varied when increasing C.\n",
    "\n",
    "This affects the coefficients for the most part by making them go further from zero, meaning negative values are decreasing and positive values are increasing. I think this means my model is overfit when a high C value is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Lower the C value.\n",
    "\n",
    "2) Adjust the penalty to minimize features with collinearity.\n",
    "\n",
    "3) Decrease number of parameters used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. How might you deal with the imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weights to the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression because I can evaluate the coefficients easily to see which had the largest impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Instantiate, fit, and score a logistic regression model with no regularization. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr3 = LogisticRegression(max_iter = 1000)\n",
    "logr3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849153084052413"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8477011494252874"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05603626074334529"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr3.coef_[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the answer for Q1 increases on the scale the probability of which hand the person uses moves in a negative direction, towards right-handed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose Logistic Regression with a C value of 0.001. This gave me the highest average score with little variation in score among my test groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, max_iter=1000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr = LogisticRegression(C = 0.001, max_iter = 1000)\n",
    "logr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) If a person playfully insults their friends, how does the probability of being left-handed change?\n",
    "\n",
    "2) If a person enjoys dancing alone, how does the probability of being left-handed change?\n",
    "\n",
    "3) If a person hates shopping, how does the probability of being left-handed change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.028058293091666277, -0.014567496244366776, -0.013490796847299438)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer to question 1:\n",
    "logr.coef_[0][22], logr.coef_[1][22], logr.coef_[2][22]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A person who playfully insults their friends is positively correlated with using their right hand and negatively correlated with using their left hand or both hands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011284472142556222, -0.0015593742753624029, -0.009725097867193838)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer to question 2:\n",
    "logr.coef_[0][13], logr.coef_[1][13], logr.coef_[2][13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A person who enjoys dancing alone is positively correlated with using their right hand and negatively correlated with using their left hand or both hands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.013208192946627572, -0.009401461050986168, 0.022609653997613725)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer to question 3:\n",
    "logr.coef_[0][32], logr.coef_[1][32], logr.coef_[2][32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A person who hates shopping is negatively correlated using their right hand or left hand and positively correlated with using both hands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
